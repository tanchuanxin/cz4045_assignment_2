# Word-level language modeling (FNN, LSTM, Transformer)

### Installation and Required Packages
We have already included the dataset here in the ```data/wikitext-2 folder```. All that is required is to install the python packages 
```bash 
pip install -r requirements.txt # Install required python packages
```

### Running Guide
We have simplified the model running into shell scripts. Please run these shell scripts on a GPU-enabled machine
```bash
sh batch.sh             # Trains FNN, LSTM and Transformer models with Adam Optimzer with both tied and not tied weights
sh rms_batch.sh         # Trains FNN Model with RMS Optimizer for comparison of results with Adam optimizer run in batch.sh
sh generate_text.sh     # Generate text for all models from batch.sh and rms_batch.sh  
```

Do not run ```sh generate_text.sh``` before you run the other two scripts. It requires the model files to be generated in order to produce text predictions. Model files are too large to host on github, or to submit. Please access them through this <a href="https://entuedu-my.sharepoint.com/:u:/g/personal/ctan184_e_ntu_edu_sg/EVBndQO15mNEs3H2zbtjqCEB7x2uWNQQPkqCQMQJ5Vh-dA?e=ynoyrJ"> LINK </a> to download them instead. Please download them or run the first two shell scripts before running the third.

### Outputs
We log the metrics and the generated texts in separate folders. Please open the respective folders to take a look
```bash
generated               # 1000 word text generated by our models
logs                    # csv files logging the perplexity score and validation loss
models                  # stores the model .pt files that can be used to recreate models and generate predictions
```

### Visualization
```bash
jupyter_notebooks/Visualization.ipynb   # contains some of the graphs that we have chosen to visualize
```
